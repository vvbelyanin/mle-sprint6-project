# docker-compose.yaml
#
# This Docker Compose file configures services for a full ML platform:
# - FastAPI for the web service
# - MLflow for tracking machine learning experiments
# - Grafana for monitoring and visualization
# - Graphite for metrics collection
# - Airflow for managing workflows
# Each service has dependencies to ensure the correct startup order.

services:
  fastapi:
    build: .  # Build FastAPI service from the current directory
    container_name: fastapi_app  # Name of the FastAPI container
    ports:
      - "${FASTAPI_PORT}:${FASTAPI_PORT}"  # Expose FastAPI on port specified by environment variable (host:container)
    depends_on:  # FastAPI depends on MLflow and Graphite to be ready first
      - mlflow
      - graphite
    env_file:
      - .env  # Load environment variables from the .env file

  mlflow:
    build: .  # Build MLflow service from the current directory (using the Dockerfile for FastAPI)
    container_name: mlflow  # Name of the MLflow container
    env_file: 
      - .env  # Load environment variables from the .env file
    command:
      - mlflow
      - server
      - --backend-store-uri=postgresql://${DB_DESTINATION_USER}:${DB_DESTINATION_PASSWORD}@${DB_DESTINATION_HOST}:${DB_DESTINATION_PORT}/${DB_DESTINATION_NAME}  # MLflow backend store URI (PostgreSQL)
      - --registry-store-uri=postgresql://${DB_DESTINATION_USER}:${DB_DESTINATION_PASSWORD}@${DB_DESTINATION_HOST}:${DB_DESTINATION_PORT}/${DB_DESTINATION_NAME}  # Registry store URI (PostgreSQL)
      - --default-artifact-root=s3://${S3_BUCKET_NAME}  # Root location for MLflow artifacts (S3 bucket)
      - --host=0.0.0.0  # Bind MLflow server to all network interfaces
      - --no-serve-artifacts  # Artifacts are stored in S3; MLflow won't serve them
    ports:
      - "${MLFLOW_PORT}:${MLFLOW_PORT}"  # Expose MLflow server on port specified by environment variable (host:container)
    depends_on:  # MLflow service depends on Graphite to be running first
      - graphite
    volumes:
      - ./mlruns:/mlflow/artifacts  # Mount the local directory for storing MLflow artifacts

  grafana:
    image: grafana/grafana  # Use the official Grafana image
    container_name: grafana  # Name of the Grafana container
    ports:
      - "${GRAFANA_PORT}:${GRAFANA_PORT}"  # Expose Grafana on port specified by environment variable (host:container)
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_USER}  # Grafana admin username from environment
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASS}  # Grafana admin password from environment
    volumes:
      - ./grafana/provisioning:/etc/grafana/provisioning  # Mount the provisioning files for Grafana to configure it
    depends_on:  # Grafana depends on Graphite to collect metrics
      - graphite

  graphite:
    image: graphiteapp/graphite-statsd  # Use the official Graphite image with StatsD
    container_name: graphite  # Name of the Graphite container
    ports:
      - "${GRAPHITE_WEB_PORT}:${GRAPHITE_WEB_PORT}"  # Expose Graphite's web interface on the port specified by environment variable (host:container)
      - "${CARBON_PORT}:${CARBON_PORT}"  # Carbon port for Graphite metrics
      - "${STATSD_UDP_PORT}:${STATSD_UDP_PORT}/udp"  # StatsD UDP port for sending metrics (host:container)
      - "${STATSD_ADMIN_PORT}:${STATSD_ADMIN_PORT}"  # StatsD admin interface (host:container)

  airflow:
    container_name: airflow  # Name of the Airflow container
    env_file: 
      - .env  # Load environment variables from the .env file
    build:
      context: .  # Set the build context to the root directory
      dockerfile: airflow/Dockerfile  # Use the Dockerfile located in the airflow directory
    ports:
      - "${AIRFLOW_PORT}:${AIRFLOW_PORT}"  # Expose Airflow's web interface on the port specified by environment variable (host:container)
    environment:
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}  # AWS access key for Airflow
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}  # AWS secret key for Airflow
      - AWS_REGION=${AWS_REGION}  # AWS region for the S3 service
      - S3_ENDPOINT_URL=${S3_ENDPOINT_URL}  # Custom S3 endpoint URL (if using a service like Yandex Cloud)
