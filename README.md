README.md

#### Проект. Рекомендательные системы в банковской сфере
 - Цель: Предсказать, какой банковский продукт предложить клиенту.
 - Основные задачи: Анализ данных о клиентах, определение важных метрик, моделирование, продуктивизация модели, настройка мониторинга и дообучения.

#### Структура проекта

| # | Задача | Решение | Источник |
|:--:|:---------|:-----------|:------------|
| 1 | Исследование данных | Проведен первичный анализ данных в Jupyter Notebook, приведены описание действий и выводы| [Jupyter NB: eda.ipynb](https://github.com/vvbelyanin/mle-sprint6-project/blob/main/eda.ipynb)  
| 2 | Подготовка инфраструктуры | Создан скрипт запуска MLflow, впоследствии включен в Docker compose с остальными сервисами|	[Запуск: run_mlflow.sh](https://github.com/vvbelyanin/mle-sprint6-project/blob/main/run_mlflow.sh)
|3| Трансляция | Описание метрик приводится в Jupyter Notebook вместе с исследовательским анализом и обоснованием выбора метрик |[Jupyter NB: eda.ipynb](https://github.com/vvbelyanin/mle-sprint6-project/blob/main/eda.ipynb)  
|4| Моделирование | Проведен эксперимент с логированием в MLFlow, подготовлен sklearn пайплайн и обученная модель. | [Jupyter NB experiments.ipynb](https://github.com/vvbelyanin/mle-sprint6-project/blob/main/experiments.ipynb), модель: fitted_model.plk
|5| Продуктивизация | Модель обернута в сервис FastAPI, с реализацией ответов на внешние запросы, все реализовано в Docker compose|	[Dockerfile](https://github.com/vvbelyanin/mle-sprint6-project/blob/main/Dockerfile), [docker-compose.yaml](https://github.com/vvbelyanin/mle-sprint6-project/blob/main/docker-compose.yaml), [сервис: app.py](https://github.com/vvbelyanin/mle-sprint6-project/blob/main/app.py)
|6| Мониторинг | Реализована push-модель контроль сервиса на основе сервера graphite, передающего метрики в grafana для мониторинга | [README.md](https://github.com/vvbelyanin/mle-sprint6-project/blob/main/README.md)
|7| Документация | Процесс обработки данных, создания модели, её выкатки и сопровождения описаны ниже | [README.md](https://github.com/vvbelyanin/mle-sprint6-project/blob/main/README.md)
|8|Требования и среда | Проект проводился в виртуальном окружении, зависимости зафиксированы, воспроизводимость экспериментов соблюдалась | [requirements.txt](https://github.com/vvbelyanin/mle-sprint6-project/blob/main/requirements.txt)

#### Рабочий процесс
Датасет представляет собой данные испанского банка о приобретениях продуктов банка пользователями с '2015-01-28' по '2016-05-28' (17 периодов). Информация о продуктах представлена бинарными переменными (0/1), их всего 24, каждая из которых отражает пользование данным продуктом в текущем периоде.  
Данные необработанные, не соответствуют типам, заметное количество пропущенных значений.  
Было принято решение создать пайплайн с предобработкой "сырых" данных, на выходе которого будут бинарные предсказания.  
  
Этап исследования данных приводится в тетради  [eda.ipynb](https://github.com/vvbelyanin/mle-sprint6-project/blob/main/eda.ipynb) :
 - Начало: импорт библиотек, настройка параметров, определения функций
 - Загрузка данных, общий обзор
 - Создание таргета, сплит на обучающий/тестовый датасеты
 - Выбор метрик
 - Анализ отдельных переменных, вывод закономерностей
 - Определение функции для препроцессинга данных
 - Обзор зависимостей между признаками и таргетом с помощью средств phik, оценка высококардинальных переменных
 - Проверка препроцессинга, формирование шага предобработки общего пайплайна
 - Итоги проведения исследовательского анализа  
   
Описание этапа моделирования приведено в тетради [experiments.ipynb](https://github.com/vvbelyanin/mle-sprint6-project/blob/main/experiments.ipynb):
 - Начало: импорт библиотек, настройка параметров, определения функций
 - Запуск MLFlow
 - Обучение модели
 - Подготовка функций для встраивания модели в сервис предсказаний
 - Получение и интерпретация метрик
 - Сравнение метрик модели с константными предсказаниями
 - Итоги этапа моделирования
  
Продуктивизация представлена файлами [Dockerfile](https://github.com/vvbelyanin/mle-sprint6-project/blob/main/Dockerfile), [docker-compose.yaml](https://github.com/vvbelyanin/mle-sprint6-project/blob/main/docker-compose.yaml), [app.py](https://github.com/vvbelyanin/mle-sprint6-project/blob/main/app.py), а также вспомогательный  [data_utils.py](https://github.com/vvbelyanin/mle-sprint6-project/blob/main/data_utils.py).  
Каждый файл снабжен своими комментариями, далее описывается общая логика.  
Обученная модель хранится в локальном каталоге /models и в хранилище MLFlow.  
Все сервисы обернуты в docker-контейнеры и запускаются единым скриптом docker composer.  
Таким образом, в дальнейшем можно управлять экспериментами, собирать и мониторить данные в рамках объединенного сервиса.  
  
Сервис предсказаний реализован с помощью фреймворка FastAPI.  
Интерфейс включает 3 эндпоинта:
 - "/": для проверки статуса сервиса
 - "/predict": непосредственно для предсказаний, принимает POST-запрос с необработанными json-данными, выдает предсказания на руском языке в виде словаря: {"Название продукта": [0,1]}
 - "/random": для тестирования сервиса в диапазоне случайных значений, выдает случайное предсказание
  
Инфраструктура реализована на платформе MLFlow.  
Это дает возможность поддерживать весь цикл ML, в частности, хранить актуальную версию модели для сервиса предсказаний.  
  
Сбор метрик производится в python коде проекта и передается клиенту сервиса мониторинга Graphite.  
В проекте производится генерация следующих метрик:
 - 'bank-rs.system.cpu_load': текущая нагрузка на CPU
 - 'bank-rs.system.memory_free_mb': свободная память
 - 'bank-rs.system.up_time': время работы сервиса
 - 'response_code.200': счетчик успешных HTTP-запросов
 - 'response_time': время отклика (время получения предсказания)
 - 'target.*': непосредственно полученные предсказания (счетчик положительных предсказаний для каждого таргета)
  
Средства визуализации Graphite довольно скудны, поэтому для отображения используется платформа Grafana.  
Все перечисленные метрики выводятся в виде настраиваемых, масштабируемых, pretty-looking элементов визуализации:  счетчиков, time-series графиков и многого другого.
Для тестирования сервиса используется скрипт run_mimic_load, имитирующий нагрузку на сервис, выдавая случайные предсказания.

#### Основной итог
В проекте удалось реализовать сервис предсказаний для рекомендации клиентам банковских продуктов.  Был построен пайплайн обрабоки данных и обучения модели, развернута структура логирования и проведения экспериментов. Основной и вспомогательные сервис поднимаются в контейнерах docker, их работа контролируется метриками с визуализацией.
